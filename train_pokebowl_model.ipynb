{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poke Bowl Inventory - YOLO Model Training\n",
    "\n",
    "This notebook trains a YOLOv8 model for detecting 40 different product classes in the Poke Bowl inventory system.\n",
    "\n",
    "## Training Improvements:\n",
    "- GPU acceleration (CUDA/MPS)\n",
    "- Proper data augmentation (mosaic, mixup, rotation, scaling, color jitter)\n",
    "- Optimized hyperparameters\n",
    "- Extended training epochs\n",
    "- Learning rate scheduling\n",
    "- Early stopping with patience\n",
    "- Comprehensive validation metrics\n",
    "- Model checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python pillow matplotlib seaborn pandas numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon) available\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected, training will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATASET_PATH = PROJECT_ROOT / 'dataset' / 'pokebowl_dataset'\n",
    "DATA_YAML = DATASET_PATH / 'data.yaml'\n",
    "TRAIN_IMAGES = DATASET_PATH / 'images' / 'train'\n",
    "VAL_IMAGES = DATASET_PATH / 'images' / 'val'\n",
    "TRAIN_LABELS = DATASET_PATH / 'labels' / 'train'\n",
    "VAL_LABELS = DATASET_PATH / 'labels' / 'val'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Data YAML: {DATA_YAML}\")\n",
    "print(f\"\\nChecking paths...\")\n",
    "print(f\"Train images exist: {TRAIN_IMAGES.exists()}\")\n",
    "print(f\"Val images exist: {VAL_IMAGES.exists()}\")\n",
    "print(f\"Train labels exist: {TRAIN_LABELS.exists()}\")\n",
    "print(f\"Val labels exist: {VAL_LABELS.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display dataset configuration\n",
    "with open(DATA_YAML, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(f\"Number of classes: {data_config['nc']}\")\n",
    "print(f\"\\nClass names:\")\n",
    "for i, name in enumerate(data_config['names']):\n",
    "    print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images and labels\n",
    "train_images = list(TRAIN_IMAGES.glob('*.jpg'))\n",
    "val_images = list(VAL_IMAGES.glob('*.jpg'))\n",
    "train_labels = list(TRAIN_LABELS.glob('*.txt'))\n",
    "val_labels = list(VAL_LABELS.glob('*.txt'))\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Training labels: {len(train_labels)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")\n",
    "print(f\"Validation labels: {len(val_labels)}\")\n",
    "print(f\"Total images: {len(train_images) + len(val_images)}\")\n",
    "print(f\"\\nImages per class (average): {(len(train_images) + len(val_images)) / data_config['nc']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "def count_class_instances(label_files, num_classes):\n",
    "    \"\"\"Count instances of each class in label files\"\"\"\n",
    "    class_counts = np.zeros(num_classes, dtype=int)\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    class_id = int(parts[0])\n",
    "                    if 0 <= class_id < num_classes:\n",
    "                        class_counts[class_id] += 1\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "train_class_counts = count_class_instances(train_labels, data_config['nc'])\n",
    "val_class_counts = count_class_instances(val_labels, data_config['nc'])\n",
    "total_class_counts = train_class_counts + val_class_counts\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(f\"{'Class ID':<10} {'Class Name':<40} {'Train':<8} {'Val':<8} {'Total':<8}\")\n",
    "print(\"-\" * 80)\n",
    "for i, name in enumerate(data_config['names']):\n",
    "    print(f\"{i:<10} {name:<40} {train_class_counts[i]:<8} {val_class_counts[i]:<8} {total_class_counts[i]:<8}\")\n",
    "\n",
    "print(f\"\\nTotal instances: {total_class_counts.sum()}\")\n",
    "print(f\"Average instances per class: {total_class_counts.mean():.1f}\")\n",
    "print(f\"Min instances: {total_class_counts.min()}\")\n",
    "print(f\"Max instances: {total_class_counts.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Bar plot\n",
    "x = np.arange(len(data_config['names']))\n",
    "ax1.bar(x, train_class_counts, label='Train', alpha=0.7)\n",
    "ax1.bar(x, val_class_counts, bottom=train_class_counts, label='Val', alpha=0.7)\n",
    "ax1.set_xlabel('Class ID', fontsize=12)\n",
    "ax1.set_ylabel('Number of Instances', fontsize=12)\n",
    "ax1.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Horizontal bar plot with names\n",
    "sorted_indices = np.argsort(total_class_counts)[::-1]\n",
    "sorted_names = [data_config['names'][i] for i in sorted_indices]\n",
    "sorted_counts = total_class_counts[sorted_indices]\n",
    "\n",
    "y_pos = np.arange(len(sorted_names))\n",
    "ax2.barh(y_pos, sorted_counts, alpha=0.7)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(sorted_names, fontsize=8)\n",
    "ax2.set_xlabel('Total Instances', fontsize=12)\n",
    "ax2.set_title('Classes Sorted by Frequency', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClass distribution plot saved as 'class_distribution.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with annotations\n",
    "def visualize_sample_images(image_files, label_files, class_names, num_samples=6):\n",
    "    \"\"\"Visualize random sample images with their annotations\"\"\"\n",
    "    samples = np.random.choice(len(image_files), min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, sample_idx in enumerate(samples):\n",
    "        img_path = image_files[sample_idx]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Find corresponding label file\n",
    "        label_path = None\n",
    "        for lbl in label_files:\n",
    "            if lbl.stem == img_path.stem:\n",
    "                label_path = lbl\n",
    "                break\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        if label_path and label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                        \n",
    "                        # Convert YOLO format to pixel coordinates\n",
    "                        x1 = int((x_center - width/2) * w)\n",
    "                        y1 = int((y_center - height/2) * h)\n",
    "                        x2 = int((x_center + width/2) * w)\n",
    "                        y2 = int((y_center + height/2) * h)\n",
    "                        \n",
    "                        # Draw rectangle and label\n",
    "                        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "                        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                        \n",
    "                        # Add class name\n",
    "                        class_name = class_names[class_id] if class_id < len(class_names) else f\"Class {class_id}\"\n",
    "                        label_text = f\"{class_name}\"\n",
    "                        \n",
    "                        # Draw label background\n",
    "                        (text_w, text_h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                        cv2.rectangle(img, (x1, y1 - text_h - 4), (x1 + text_w, y1), color, -1)\n",
    "                        cv2.putText(img, label_text, (x1, y1 - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_path.name}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualizing sample training images...\")\n",
    "visualize_sample_images(train_images, train_labels, data_config['names'], num_samples=6)\n",
    "print(\"Sample images saved as 'sample_images.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine deviceif torch.cuda.is_available():    device = 0  # Use first GPU    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")elif torch.backends.mps.is_available():    device = 'mps'  # Use Apple Silicon GPU    print(\"Using MPS (Apple Silicon GPU)\")else:    device = 'cpu'    print(\"WARNING: Using CPU - training will be very slow!\")# Training hyperparameters (FIXED for tensor size mismatch)TRAINING_CONFIG = {    # Model    'model': 'yolov8n.pt',  # Nano model (fastest, good for edge devices)        # Dataset    'data': str(DATA_YAML),        # Training duration    'epochs': 200,    'patience': 50,        # Batch and image size    'batch': 8,  # Reduced from 16    'imgsz': 640,        # Device    'device': device,    'workers': 4,  # Reduced from 8        # Optimization    'optimizer': 'AdamW',    'lr0': 0.001,    'lrf': 0.01,    'momentum': 0.937,    'weight_decay': 0.0005,    'warmup_epochs': 3.0,    'warmup_momentum': 0.8,    'warmup_bias_lr': 0.1,        # Data augmentation (REDUCED to fix errors)    'hsv_h': 0.015,    'hsv_s': 0.7,    'hsv_v': 0.4,    'degrees': 5.0,   # Reduced from 10    'translate': 0.1, # Reduced from 0.2    'scale': 0.5,     # Reduced from 0.9    'shear': 2.0,     # Reduced from 5.0    'perspective': 0.0,  # Disabled    'flipud': 0.0,    'fliplr': 0.5,    'mosaic': 0.0,  # DISABLED (causes tensor issues)    'mixup': 0.0,     # DISABLED (causes tensor issues)    'copy_paste': 0.0,  # DISABLED (causes tensor issues)    'auto_augment': 'randaugment',    'erasing': 0.4,    'close_mosaic': 10,        # Loss weights    'box': 7.5,    'cls': 0.5,    'dfl': 1.5,        # Validation    'val': True,    'plots': True,    'save': True,    'save_period': 10,        # Other    'cache': False,    'amp': True,    'pretrained': True,    'verbose': True,    'seed': 42,    'deterministic': True,    'rect': False,  # Disabled for stability        # Project settings    'project': 'runs/train',    'name': f'pokebowl_yolov8n_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',    'exist_ok': True,}print(\"\\nTraining Configuration:\")print(\"=\" * 60)for key, value in TRAINING_CONFIG.items():    print(f\"{key:<20}: {value}\")print(\"=\" * 60)print(\"\\n\u26a0\ufe0f  NOTE: mixup and copy_paste disabled to fix tensor size mismatch error\")print(\"This is normal for datasets with varying annotation counts per image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(f\"\\nInitializing YOLO model: {TRAINING_CONFIG['model']}\")\n",
    "model = YOLO(TRAINING_CONFIG['model'])\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Model type: {type(model.model)}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training will run for up to {TRAINING_CONFIG['epochs']} epochs\")\n",
    "print(f\"Early stopping patience: {TRAINING_CONFIG['patience']} epochs\")\n",
    "print(f\"Device: {TRAINING_CONFIG['device']}\")\n",
    "print(f\"Batch size: {TRAINING_CONFIG['batch']}\")\n",
    "print(f\"Image size: {TRAINING_CONFIG['imgsz']}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(**TRAINING_CONFIG)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training results directory\n",
    "results_dir = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name']\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(f\"Results exist: {results_dir.exists()}\")\n",
    "\n",
    "if results_dir.exists():\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for file in sorted(results_dir.glob('*')):\n",
    "        if file.is_file():\n",
    "            size = file.stat().st_size / (1024 * 1024)  # MB\n",
    "            print(f\"  {file.name:<40} {size:>8.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "results_img = results_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    img = plt.imread(str(results_img))\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Training Results', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Results plot not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix_img = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    img = plt.imread(str(confusion_matrix_img))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Confusion matrix not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display validation batch predictions\n",
    "val_batch_imgs = list(results_dir.glob('val_batch*_pred.jpg'))\n",
    "if val_batch_imgs:\n",
    "    print(f\"Found {len(val_batch_imgs)} validation batch prediction images\\n\")\n",
    "    \n",
    "    # Display first 3 batches\n",
    "    for i, img_path in enumerate(sorted(val_batch_imgs)[:3]):\n",
    "        img = plt.imread(str(img_path))\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Validation Batch {i} Predictions', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No validation batch predictions found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    best_model = YOLO(str(best_model_path))\n",
    "    print(\"Best model loaded successfully!\")\n",
    "    \n",
    "    # Validate the model\n",
    "    print(\"\\nRunning validation...\")\n",
    "    metrics = best_model.val(data=str(DATA_YAML), imgsz=640, batch=16, device=device)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDATION METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Best model not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation images\n",
    "if best_model_path.exists():\n",
    "    # Select random validation images\n",
    "    test_images = np.random.choice(val_images, min(6, len(val_images)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, img_path in enumerate(test_images):\n",
    "        # Run inference\n",
    "        results = best_model.predict(str(img_path), conf=0.25, iou=0.45, imgsz=640, device=device)\n",
    "        \n",
    "        # Get annotated image\n",
    "        annotated_img = results[0].plot()\n",
    "        annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(annotated_img)\n",
    "        axes[idx].set_title(f\"{img_path.name}\\nDetections: {len(results[0].boxes)}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions on Validation Images', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('test_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Test predictions saved as 'test_predictions.png'\")\n",
    "else:\n",
    "    print(\"Model not available for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to project root\n",
    "if best_model_path.exists():\n",
    "    destination = PROJECT_ROOT / 'best.pt'\n",
    "    \n",
    "    # Backup old model if exists\n",
    "    if destination.exists():\n",
    "        backup_path = PROJECT_ROOT / f'best_backup_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pt'\n",
    "        shutil.copy(destination, backup_path)\n",
    "        print(f\"Old model backed up to: {backup_path}\")\n",
    "    \n",
    "    # Copy new model\n",
    "    shutil.copy(best_model_path, destination)\n",
    "    print(f\"\\nNew best model copied to: {destination}\")\n",
    "    print(f\"Model size: {destination.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Verify model\n",
    "    print(\"\\nVerifying model...\")\n",
    "    verify_model = YOLO(str(destination))\n",
    "    print(f\"Model classes: {len(verify_model.names)}\")\n",
    "    print(f\"Model names: {list(verify_model.names.values())[:5]}...\")  # Show first 5\n",
    "    print(\"\\n\u2713 Model verification successful!\")\n",
    "else:\n",
    "    print(\"Best model not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  - Training images: {len(train_images)}\")\n",
    "print(f\"  - Validation images: {len(val_images)}\")\n",
    "print(f\"  - Number of classes: {data_config['nc']}\")\n",
    "print(f\"  - Total instances: {total_class_counts.sum()}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  - Model: {TRAINING_CONFIG['model']}\")\n",
    "print(f\"  - Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"  - Batch size: {TRAINING_CONFIG['batch']}\")\n",
    "print(f\"  - Image size: {TRAINING_CONFIG['imgsz']}\")\n",
    "print(f\"  - Device: {TRAINING_CONFIG['device']}\")\n",
    "print(f\"  - Optimizer: {TRAINING_CONFIG['optimizer']}\")\n",
    "print(f\"  - Learning rate: {TRAINING_CONFIG['lr0']}\")\n",
    "\n",
    "print(f\"\\nAugmentation:\")\n",
    "print(f\"  - Mosaic: {TRAINING_CONFIG['mosaic']}\")\n",
    "print(f\"  - Mixup: {TRAINING_CONFIG['mixup']}\")\n",
    "print(f\"  - Copy-paste: {TRAINING_CONFIG['copy_paste']}\")\n",
    "print(f\"  - Rotation: \u00b1{TRAINING_CONFIG['degrees']}\u00b0\")\n",
    "print(f\"  - Scale: \u00b1{TRAINING_CONFIG['scale']}\")\n",
    "print(f\"  - Translation: \u00b1{TRAINING_CONFIG['translate']}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\nFinal Metrics:\")\n",
    "    print(f\"  - mAP50: {metrics.box.map50:.4f}\")\n",
    "    print(f\"  - mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(f\"  - Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"  - Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  - Results directory: {results_dir}\")\n",
    "print(f\"  - Best model: {destination}\")\n",
    "print(f\"  - Training plots: {results_dir / 'results.png'}\")\n",
    "print(f\"  - Confusion matrix: {results_dir / 'confusion_matrix.png'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE! \ud83c\udf89\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThe new model has been saved to 'best.pt' and is ready for deployment.\")\n",
    "print(\"You can now use this model in your Poke Bowl Inventory System.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "After training is complete:\n",
    "\n",
    "1. **Test the model** in the actual system:\n",
    "   ```bash\n",
    "   cd backend\n",
    "   python3 main.py\n",
    "   ```\n",
    "\n",
    "2. **Monitor performance** on real camera feed\n",
    "\n",
    "3. **Collect more data** if needed:\n",
    "   - Focus on underrepresented classes\n",
    "   - Add images with different lighting conditions\n",
    "   - Include various angles and distances\n",
    "\n",
    "4. **Fine-tune** if necessary:\n",
    "   - Adjust confidence threshold in `config/config.yaml`\n",
    "   - Modify IoU threshold for better detection\n",
    "   - Retrain with more epochs if underfitting\n",
    "\n",
    "5. **Consider upgrading** to a larger model (yolov8s or yolov8m) if:\n",
    "   - You have more GPU memory\n",
    "   - You need better accuracy\n",
    "   - Inference speed is acceptable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}